# -*- coding: utf-8 -*-
"""PenelitianSkripsiMahasiswaAmikom21.61.0225.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rToXzDnJbz8Mzf5C-5XxIDCRcLzDS4fZ

# IMPORT DATA
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from collections import Counter

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/Skripsi/Amikom.csv'
df = pd.read_csv(file_path)

"""# **EDA**"""

print("Data awal")
display(df.head())

df

print("\nInformasi Data:")
df.info()

print("\nInformasi Data:")
display(df.describe(include='all'))

print("\nMissing Values (jumlah):")
print(df.isnull().sum())

print("\nJumlah Data Duplikat:")
print(df.duplicated().sum())

numerik = df.select_dtypes(include=np.number).columns
for col in numerik:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[col].dropna(), kde=True, bins=30)
    plt.title(f'Distribusi Fitur: {col}')
    plt.show()

kategori = df.select_dtypes(include='object').columns

for col in kategori:
    plt.figure(figsize=(10, 6))
    ax = sns.countplot(data=df, x=col, order=df[col].value_counts().index)
    plt.title(f'Jumlah Kategori: {col}')
    plt.xlabel(col)
    plt.ylabel('Jumlah')


    plt.xticks(rotation=45, ha='right')


    plt.tight_layout()
    plt.show()

corr_matrix = df.corr(numeric_only=True)

mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix,
            annot=True,
            fmt=".2f",             # Format angka dua digit desimal
            cmap='coolwarm',
            mask=mask,             # Masking segitiga atas
            square=True,           # Biar kotak
            linewidths=.5,         # Garis antar kotak
            cbar_kws={"shrink": .8})  # Ukuran color bar

plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(fontsize=10)
plt.title('Heatmap Korelasi Fitur Numerik', fontsize=14)
plt.tight_layout()
plt.show()

"""Alasan menggunakan heatmap korelasi seperti diatas :

1. Hanya menampilkan segitiga bawah dari matriks korelasi, sehingga tidak menampilkan informasi yang berulang.(tanpa duplikasi)
2. Membuat tampilannya lebih ringkas dan fokus.
3. Nilai-nilai korelasi ditulis dengan dua desimal, jadi pengguna bisa tahu secara kuantitatif seberapa kuat hubungan antar fitur.
4. Label sumbu X dan Y ditampilkan secara jelas dan tidak bertabrakan. Sangat penting untuk identifikasi variabel yang saling berkorelasi.


Analisis dari heatmap diatas :
1. IPS1 hingga IPS5 sangat berkorelasi tinggi satu sama lain (nilai korelasi sekitar 0.76 – 0.81), ini logis karena performa akademik antar semester sering konsisten.

2. IPK juga memiliki korelasi tinggi dengan nilai IPS semester, terutama IPS3 (0.81) dan IPS2 (0.78) → artinya, performa di semester awal-mid punya pengaruh besar terhadap IPK.

3. Rerata Kehadiran punya korelasi sedang-tinggi dengan IPK (0.58) → ini menarik: mahasiswa yang rajin hadir cenderung punya IPK lebih tinggi.

4. UsiaMasuk, THA, dan Hashed NPM tidak menunjukkan korelasi kuat dengan fitur lain (korelasi mendekati 0).
"""

for col in numerik:
    plt.figure(figsize=(10, 4))  # Ukuran horizontal agar muat
    sns.boxplot(data=df, y=col, color='skyblue', fliersize=3, linewidth=1.5)
    plt.title(f'Distribusi dan Outlier: {col}', fontsize=13)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.xlabel('Nilai')
    plt.ylabel(col)
    plt.tight_layout()
    plt.show()

"""# **Preprocessing Data**"""

# Gabungkan kelas 'Memuaskan' → 'Sangat Memuaskan' (agar tidak minor)
df['PredikatKelulusan'] = df['PredikatKelulusan'].replace({
    'Memuaskan': 'Sangat Memuaskan'
  })

kolom_dihapus = ['Hashed NPM']
df = df.drop(columns=kolom_dihapus)

# Label encode fitur kategori
kategori = df.select_dtypes(include='object').columns.drop('PredikatKelulusan')
label_encoders = {}
for col in kategori:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

"""# Outlier Dectection & Removal"""

# Data jumlah outlier per kolom
data_outlier = {
    'Kolom': [
        'THA', 'Prodi', 'Ipk', 'SksTotal', 'IPS1', 'IPS2', 'IPS3',
        'IPS4', 'IPS5', 'IPS6', 'IPS7', 'JenisKelamin', 'UsiaMasuk', 'Rerata Kehadiran'
    ],
    'Jumlah Outlier': [
        0, 0, 118, 913, 164, 336, 265, 328, 182, 160, 0, 0, 181, 12
    ]
}

# Membuat DataFrame
df_outlier = pd.DataFrame(data_outlier)

# Visualisasi bar chart
plt.figure(figsize=(12, 6))
sns.barplot(x='Jumlah Outlier', y='Kolom', data=df_outlier, palette='viridis')

plt.title('Jumlah Outlier per Kolom')
plt.xlabel('Jumlah Outlier')
plt.ylabel('Kolom')
plt.tight_layout()
plt.show()

# Fungsi deteksi dan pembersihan outlier (IQR)
def detect_outliers_iqr(data, col):
    Q1, Q3 = data[col].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    return data[(data[col] < Q1 - 1.5 * IQR) | (data[col] > Q3 + 1.5 * IQR)]

def remove_outliers_iqr(data, col):
    Q1, Q3 = data[col].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    return data[(data[col] >= Q1 - 1.5 * IQR) & (data[col] <= Q3 + 1.5 * IQR)]

# Kolom numerik yang akan dicek outlier-nya
kolom_numerik = ['Ipk', 'SksTotal', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'IPS6', 'UsiaMasuk']

# Simpan data asli
df_original = df.copy()

# Buat salinan untuk pembersihan
df_clean = df.copy()
for col in kolom_numerik:
    df_clean = remove_outliers_iqr(df_clean, col)

print(f"Jumlah data asli: {len(df_original)}")
print(f"Jumlah data bersih: {len(df_clean)}")
print(f"Outlier dibuang: {len(df_original) - len(df_clean)}")

print(df_clean.columns)
print(df_clean['SksTotal'].dtype)
print(df_clean['SksTotal'].isnull().sum())

# Cek indeks data yang termasuk outlier (dibuang setelah pembersihan)
indeks_outlier = df_original.index.difference(df_clean.index)

# Tampilkan baris-baris yang merupakan outlier
outlier_dibuang = df_original.loc[indeks_outlier]

# Tampilkan jumlah dan data outlier yang dibuang
print(f"Jumlah outlier yang dibuang: {len(outlier_dibuang)}")
display(outlier_dibuang)

for col in kolom_numerik:
    outliers_col = detect_outliers_iqr(df_original, col)
    outliers_col = outliers_col.loc[outliers_col.index.difference(df_clean.index)]
    print(f"\nOutlier yang dibuang dari kolom {col} ({len(outliers_col)} data):")
    display(outliers_col[[col]])

outlier_index_all = set()

for col in kolom_numerik:
    outlier_index = detect_outliers_iqr(df_original, col).index
    outlier_index_all.update(outlier_index)

print(f"Total baris unik yang merupakan outlier di minimal satu kolom: {len(outlier_index_all)}")

print(f"Total data yang dibuang: {len(df_original) - len(df_clean)}")

df_clean['SksTotal'].value_counts()

"""# Split Data & SMOTE"""

# Pisahkan fitur dan target
X = df_clean.drop(columns='PredikatKelulusan')
y = df_clean['PredikatKelulusan']
le_y = LabelEncoder()
y_encoded = le_y.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42
)

# Standarisasi numerik
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Terapkan SMOTE (pastikan k_neighbors < jumlah sample kelas terkecil)
min_class = min(Counter(y_train).values())
k = min(5, min_class - 1)
smote = SMOTE(random_state=42, k_neighbors=k)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

# Distribusi label sebelum dan sesudah SMOTE
fig, axes = plt.subplots(1, 2, figsize=(14, 6))
sns.countplot(x=y_train, ax=axes[0], palette="pastel")
axes[0].set_title("Distribusi Label Sebelum SMOTE")
sns.countplot(x=y_train_smote, ax=axes[1], palette="pastel")
axes[1].set_title("Distribusi Label Setelah SMOTE")
plt.tight_layout()
plt.show()

# Heatmap Korelasi
plt.figure(figsize=(16, 7))

plt.subplot(1, 2, 1)
sns.heatmap(
    df_original.corr(numeric_only=True).round(2),
    annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=True,
    annot_kws={"size": 9}
)
plt.title('Korelasi - Original', fontsize=14)

plt.subplot(1, 2, 2)
sns.heatmap(
    df_clean.corr(numeric_only=True).round(2),
    annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=True,
    annot_kws={"size": 9}
)
plt.title('Korelasi - Clean', fontsize=14)

plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.countplot(data=df_original, x='PredikatKelulusan', color='skyblue')
plt.title('Predikat Kelulusan - Original')
plt.xticks(rotation=30)

plt.subplot(1, 2, 2)
sns.countplot(data=df_clean, x='PredikatKelulusan', color='skyblue')
plt.title('Predikat Kelulusan - Clean')
plt.xticks(rotation=30)

plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6))

# Plot untuk data original
plt.subplot(1, 2, 1)
ax1 = sns.countplot(data=df_original, x='PredikatKelulusan', color='skyblue')
plt.title('Predikat Kelulusan - Original', fontsize=14)
plt.xticks(rotation=30)
for p in ax1.patches:
    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2, p.get_height()),
                 ha='center', va='bottom', fontsize=10)

# Plot untuk data clean
plt.subplot(1, 2, 2)
ax2 = sns.countplot(data=df_clean, x='PredikatKelulusan', color='skyblue')
plt.title('Predikat Kelulusan - Clean', fontsize=14)
plt.xticks(rotation=30)
for p in ax2.patches:
    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2, p.get_height()),
                 ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""# Modeling"""

# Logistic Regression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_smote, y_train_smote)

y_pred_lr = lr_model.predict(X_test_scaled)

print("=== Logistic Regression ===")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Classification Report:")
print(classification_report(y_test, y_pred_lr, target_names=le_y.classes_))

# Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Blues',
            xticklabels=le_y.classes_, yticklabels=le_y.classes_)
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train_smote, y_train_smote)

y_pred_nb = nb_model.predict(X_test_scaled)

print("\n=== Naive Bayes ===")
print("Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Classification Report:")
print(classification_report(y_test, y_pred_nb, target_names=le_y.classes_))

# Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_nb), annot=True, fmt='d', cmap='Greens',
            xticklabels=le_y.classes_, yticklabels=le_y.classes_)
plt.title('Confusion Matrix - Naive Bayes')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Data hasil evaluasi
data_evaluation = {
    'Model': ['Logistic Regression', 'Naive Bayes'],
    'Accuracy': [0.8076, 0.7972],
    'Precision': [0.81, 0.80],
    'Recall': [0.80, 0.79],
    'F1-score': [0.81, 0.79]
}

# Konversi ke DataFrame
df_eval = pd.DataFrame(data_evaluation)

# Mengubah data menjadi long format agar mudah divisualisasikan dengan seaborn
df_melted = df_eval.melt(id_vars='Model', var_name='Metric', value_name='Value')

# Visualisasi
plt.figure(figsize=(10, 6))
sns.barplot(x='Metric', y='Value', hue='Model', data=df_melted, palette='Set2')

plt.ylim(0.7, 0.85)
plt.title('Perbandingan Kinerja Model')
plt.ylabel('Skor')
plt.xlabel('Metrik Evaluasi')
plt.legend(title='Model')
plt.tight_layout()
plt.show()

"""# KEEP DULU"""

# --- Step 2: Pisahkan fitur (X) dan target (y) ---
X = df.drop(columns='PredikatKelulusan')
y = df['PredikatKelulusan']

# Encode label y (Target)
le_y = LabelEncoder()
y_encoded = le_y.fit_transform(y)  # y_encoded is numeric

# --- Step 3: Split data ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42
)

# Tampilkan distribusi label sebelum SMOTE
print("Distribusi label sebelum SMOTE:", dict(Counter(y_train)))

# --- Step 4: Standarisasi fitur X SAJA ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Step 5: Terapkan SMOTE ---
# Hitung distribusi label untuk deteksi kelas minor
label_counts = Counter(y_train)
min_class = min(label_counts.values())

# Cegah error: sesuaikan k_neighbors jika perlu
k = min(5, min_class - 1)  # k_neighbors harus < jumlah sample kelas terkecil

smote = SMOTE(random_state=42, k_neighbors=k)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

print("Distribusi label setelah SMOTE:", dict(Counter(y_train_smote)))

# Buat figure
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Plot sebelum SMOTE
sns.countplot(x=y_train, ax=axes[0], palette="pastel")
axes[0].set_title("Distribusi Label Sebelum SMOTE")
axes[0].set_xlabel("Label")
axes[0].set_ylabel("Jumlah")
for p in axes[0].patches:
    axes[0].annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                     ha='center', va='bottom', fontsize=10)

# Plot sesudah SMOTE
sns.countplot(x=y_train_smote, ax=axes[1], palette="pastel")
axes[1].set_title("Distribusi Label Setelah SMOTE")
axes[1].set_xlabel("Label")
axes[1].set_ylabel("Jumlah")
for p in axes[1].patches:
    axes[1].annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                     ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

# Simpan kolom target sebelum proses scaling
target_col = 'PredikatKelulusan'
y = df[target_col]  # Jangan modifikasi ini
X = df.drop(columns=[target_col])

# Label encoding untuk fitur kategorikal (jika ada)
kategori = X.select_dtypes(include='object').columns

label_encoders = {}
for col in kategori:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le

# Gabungkan kembali X dan y menjadi df baru
df = pd.concat([X, y], axis=1)

print("Dataset setelah preprocessing:")
display(df.head())

def detect_outliers_iqr(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = data[(data[col] < lower) | (data[col] > upper)]
    return outliers

#Cek outlier untuk semua kolom numerik
numerik = df.select_dtypes(include=['int64', 'float64']).columns

for col in numerik:
    outliers = detect_outliers_iqr(df, col)
    print(f"Kolom: {col}")
    print(f"Jumlah outlier: {len(outliers)}")
    print("-" * 30)

df['is_outlier'] = 0

for col in ['Ipk', 'SksTotal', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'IPS6', 'UsiaMasuk']:
    outliers = detect_outliers_iqr(df, col)
    df.loc[outliers.index, 'is_outlier'] = 1

df_original = df.copy()

kolom_outlier = ['Ipk', 'SksTotal', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'IPS6', 'UsiaMasuk']

df_clean = df.copy()

# Fungsi untuk menghapus outlier menggunakan IQR
def remove_outliers_iqr(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return data[(data[col] >= lower) & (data[col] <= upper)]

# Bersihkan semua kolom outlier
for col in kolom_outlier:
    df_clean = remove_outliers_iqr(df_clean, col)

print(f"Jumlah data (original): {len(df_original)}")
print(f"Jumlah data (clean): {len(df_clean)}")
print(f"Data yang dibuang karena outlier: {len(df_original) - len(df_clean)}")

# Statistik numerik dari kedua dataset
print("Statistik Deskriptif Dataset Asli")
display(df_original.describe())

print("\nStatistik Deskriptif Dataset Bersih")
display(df_clean.describe())

numerik = ['Ipk', 'SksTotal', 'IPS1', 'IPS2', 'IPS3', 'IPS4', 'IPS5', 'IPS6', 'UsiaMasuk']

for col in numerik:
    plt.figure(figsize=(10, 4))

    # Histogram original
    plt.subplot(1, 2, 1)
    sns.histplot(df_original[col], bins=30, kde=True, color='orange')
    plt.title(f'{col} - Original')

    # Histogram clean
    plt.subplot(1, 2, 2)
    sns.histplot(df_clean[col], bins=30, kde=True, color='green')
    plt.title(f'{col} - Clean')

    plt.tight_layout()
    plt.show()

# Set style
sns.set(style="white")

# Buat figure
plt.figure(figsize=(16, 7))

# Heatmap original
plt.subplot(1, 2, 1)
sns.heatmap(
    df_original.corr(numeric_only=True).round(2),  # Bulatkan nilai korelasi
    annot=True,
    cmap='coolwarm',
    fmt='.2f',
    linewidths=0.5,
    square=True,
    annot_kws={"size": 9}
)
plt.title('Korelasi - Original', fontsize=14)

# Heatmap clean
plt.subplot(1, 2, 2)
sns.heatmap(
    df_clean.corr(numeric_only=True).round(2),
    annot=True,
    cmap='coolwarm',
    fmt='.2f',
    linewidths=0.5,
    square=True,
    annot_kws={"size": 9}
)
plt.title('Korelasi - Clean', fontsize=14)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Misalnya label kelulusan berada di kolom 'PredikatKelulusan'
# Dan fitur lainnya adalah kolom numerik
X = df.drop(columns=['PredikatKelulusan'])
y = df['PredikatKelulusan']

# One-hot encoding untuk fitur kategorikal (otomatis mendeteksi kolom string)
X_encoded = pd.get_dummies(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)

# Scaling hanya fitur numerik hasil encoding
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Logistic Regression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_scaled, y_train)
y_pred_lr = lr_model.predict(X_test_scaled)

# Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train_scaled, y_train)
y_pred_nb = nb_model.predict(X_test_scaled)

# Logistic Regression report
print("=== Logistic Regression ===")
print(classification_report(y_test, y_pred_lr))

# Naive Bayes report
print("=== Naive Bayes ===")
print(classification_report(y_test, y_pred_nb))

def plot_conf_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y))
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=np.unique(y), yticklabels=np.unique(y))
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {title}')
    plt.show()

# Visualisasi
plot_conf_matrix(y_test, y_pred_lr, "Logistic Regression")
plot_conf_matrix(y_test, y_pred_nb, "Naive Bayes")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Menyimpan skor
scores = {
    'Model': ['Logistic Regression', 'Naive Bayes'],
    'Accuracy': [
        accuracy_score(y_test, y_pred_lr),
        accuracy_score(y_test, y_pred_nb)
    ],
    'Macro Precision': [
        precision_score(y_test, y_pred_lr, average='macro'),
        precision_score(y_test, y_pred_nb, average='macro')
    ],
    'Macro Recall': [
        recall_score(y_test, y_pred_lr, average='macro'),
        recall_score(y_test, y_pred_nb, average='macro')
    ],
    'Macro F1': [
        f1_score(y_test, y_pred_lr, average='macro'),
        f1_score(y_test, y_pred_nb, average='macro')
    ]
}

df_scores = pd.DataFrame(scores).melt(id_vars='Model', var_name='Metric', value_name='Value')

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x='Metric', y='Value', hue='Model', data=df_scores, palette='muted')
plt.title('Perbandingan Kinerja Model')
plt.ylim(0, 1)
plt.legend(title='Model')
plt.tight_layout()
plt.show()